{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to set device\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "# torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for image data\n",
    "path = Path(\"path of folder containing image data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Databunch to get data from folders where each folder will be treated as a single class\n",
    "# valid pct = split for training and validation\n",
    "# bs = batch_size\n",
    "# ds_tfms are transformation which will be used on image_data by deafult we use \"get_transforma()\" which by\n",
    "# deafult does horizontal flip and other transformtaions like rotation, lighting, etc.\n",
    "\n",
    "\n",
    "databunch = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n",
    "    ds_tfms=get_transforms(), size=448, bs = 4, num_workers=4).normalize(imagenet_stats)\n",
    "\n",
    "\n",
    "# to avoid horizontal flip and rotation uncomment the 2 lines below\n",
    "\n",
    "# databunch = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n",
    "#     ds_tfms=get_transforms(do_flip=False, max_rotate=0), size=size, bs = bs, num_workers=4).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to know more about the databunch you have created\n",
    "# print(data.classes, data.c)\n",
    "# data.show_batch(10, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the best learning rate for training uncomment the last two lines(it's not necessary just use 1e-3 for lr)\n",
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here databunch are data which is defined above \"models.resnet34\" is architecture\n",
    "# to choose other architectures type \"models.\" and then press \"TAB\"\n",
    "# to use metrics other than accuracy go to the following link [fastai_metrics](https://docs.fast.ai/metrics.html#Training-metrics) \n",
    "# you can write your own function for metrics(it's pretty easy)\n",
    "\n",
    "learn = cnn_learner(databunch, models.densenet201, metrics=accuracy)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use efficient-net in fastai then run this cell:\n",
    "# model = EfficientNet.from_name('efficientnet-b1')\n",
    "# model._fc = nn.Linear(1280, data.c)\n",
    "# learn = Learner(data, model, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to free_up some space \n",
    "# torch.cuda.empty_cache() \n",
    "# learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model can also be trained on multiple GPUs using\n",
    "# learn.model = torch.nn.DataParallel(learn.model, device_ids=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.050130</td>\n",
       "      <td>0.555015</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.068513</td>\n",
       "      <td>0.655165</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.980125</td>\n",
       "      <td>0.951555</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.828842</td>\n",
       "      <td>0.622180</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.787156</td>\n",
       "      <td>0.546933</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.807844</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.745200</td>\n",
       "      <td>0.561863</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.520234</td>\n",
       "      <td>0.473378</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.449294</td>\n",
       "      <td>0.467562</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.502472</td>\n",
       "      <td>0.445076</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.8026315569877625.\n",
      "Better model found at epoch 8 with accuracy value: 0.8289473652839661.\n",
      "Better model found at epoch 9 with accuracy value: 0.8421052694320679.\n"
     ]
    }
   ],
   "source": [
    "# to start training run this cell, first argument is epoch and second one is learning rate \n",
    "# to train different layer groups with different learning rates use \"slice(1e-6, 1e-4)\"\n",
    "\n",
    "\n",
    "# learn.fit_one_cycle(10, 1e-3)\n",
    "\n",
    "\n",
    "# in the above case the model will not be saved instead it will create a \"tmp.pth\" file for model and it will be saved\n",
    "# when we call learn.save\n",
    "# to save the best fit model based on the accuracy during training without worrying about overfittng\n",
    "# uncomment the last line\n",
    "# here monitor is the judge to save model it can be changed to training loss or validation loss and best is the name for model\n",
    "\n",
    "learn.fit_one_cycle(10, 1e-3, callbacks=[SaveModelCallback(learn, every='improvement', monitor='accuracy', name='best')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     to save and load the model uncomment the below two lines\n",
    "#     learn.save(\"name of model.pth\")\n",
    "\n",
    "#     if you are using best fit callback in learner no need to save model just load the model with the saved name\n",
    "#     learn.load(\"name of model.pth\")\n",
    "\n",
    "#     to save without optimizer data(it will have no effect on accuracy but you can't resume training from where you left)\n",
    "#     it will reduce size of model\n",
    "#     learn.save(\"name of model.pth\", with_opt=False)\n",
    "\n",
    "#     to save using plane torch\n",
    "#     torch.save(learn.model, \"./final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the results\n",
    "# learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to export and save the whole learner and load for next time\n",
    "learn.export(\"model.pkl\")\n",
    "\n",
    "# and to load\n",
    "# load_learner(path, 'name .pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reduce the size of model further the model can be trained in fp16 and to do this\n",
    "# just convert the learner i.e, \"learn.to_fp16\" before training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to only save state_dict of model\n",
    "# torch.save({'state_dict': learn.model.state_dict()}, './name .pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
